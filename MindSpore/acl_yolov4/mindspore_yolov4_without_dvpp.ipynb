{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe328759-7068-4eb1-bcc5-b3e691810430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import sys\n",
    "from model import preprocess\n",
    "from model import post_process\n",
    "#path = os.path.dirname(os.path.abspath(__file__))\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "sys.path.append('../acllite')\n",
    "\n",
    "from acllite_model import AclLiteModel\n",
    "from acllite_resource import AclLiteResource\n",
    "import constants as const\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a64e96-0743-49a8-b0a3-ea6a13b85f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = './data/'\n",
    "OUTPUT_DIR = './out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485ee6b5-6667-4fff-b44e-a2c5dccedeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 5\n",
    "model_path = './model/yolov4_bs1.om'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4ba8ef-6a74-4781-9413-bb1c93ea095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init resource stage:\n",
      "Init resource success\n",
      "[Device] NPU Device id: 5\n",
      "Init model resource start...\n",
      "[AclLiteModel] create model output dataset:\n",
      "malloc output 0, size 368220\n",
      "malloc output 1, size 1472880\n",
      "malloc output 2, size 5891520\n",
      "Create model output dataset success\n",
      "Init model resource success\n"
     ]
    }
   ],
   "source": [
    "acl_resource = AclLiteResource(device_id)\n",
    "acl_resource.init()\n",
    "print('[Device] NPU Device id:',acl_resource.device_id)\n",
    "model = AclLiteModel(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ced9007-1aef-4e30-b1cd-7f56452f5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = [os.path.join(INPUT_DIR, img)\n",
    "                   for img in os.listdir(INPUT_DIR)\n",
    "                   if os.path.splitext(img)[1] in const.IMG_EXT]\n",
    "pic = images_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce609d1-f3c4-4864-9735-ce7b58b3b3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input size 1\n",
      "input  0\n",
      "model input dims ({'name': 'x', 'dimCount': 4, 'dims': [1, 3, 608, 608]}, 0)\n",
      "model input datatype 0\n",
      "==================================================\n",
      "model output size 3\n",
      "output  0\n",
      "model output dims ({'name': 'output_0_trans_Cast_353_0', 'dimCount': 5, 'dims': [1, 19, 19, 3, 85]}, 0)\n",
      "model output datatype 0\n",
      "output  1\n",
      "model output dims ({'name': 'output_1_trans_Cast_354_0', 'dimCount': 5, 'dims': [1, 38, 38, 3, 85]}, 0)\n",
      "model output datatype 0\n",
      "output  2\n",
      "model output dims ({'name': 'output_2_trans_Cast_355_0', 'dimCount': 5, 'dims': [1, 76, 76, 3, 85]}, 0)\n",
      "model output datatype 0\n",
      "==================================================\n",
      "[Model] class Model init resource stage success\n",
      "new_image.shape (608, 608, 3)\n",
      "post process\n",
      "pred.shape (1, 19, 19, 3, 85)\n",
      "conv_output.shape (1, 19, 19, 3, 85)\n",
      "19 19\n",
      "conv out-shape (1, 19, 19, 3, 85)\n",
      "pred-reshaped (1083, 85)\n",
      "pred[:, 5] []\n",
      "pred[:, 5] shape (0,)\n",
      "pred.shape (1, 38, 38, 3, 85)\n",
      "conv_output.shape (1, 38, 38, 3, 85)\n",
      "38 38\n",
      "conv out-shape (1, 38, 38, 3, 85)\n",
      "pred-reshaped (4332, 85)\n",
      "pred[:, 5] [33. 33.  0.  0.  0.  0.]\n",
      "pred[:, 5] shape (6,)\n",
      "pred.shape (1, 76, 76, 3, 85)\n",
      "conv_output.shape (1, 76, 76, 3, 85)\n",
      "76 76\n",
      "conv out-shape (1, 76, 76, 3, 85)\n",
      "pred-reshaped (17328, 85)\n",
      "pred[:, 5] [33. 33. 33. 33. 33. 33. 33. 33. 33.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "pred[:, 5] shape (21,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#read image\n",
    "bgr_img = cv.imread(pic)\n",
    "#preprocess\n",
    "data, orig = preprocess(pic,model._model_desc)\n",
    "#Send into model inference\n",
    "result_list = model.execute([data,])    \n",
    "#Process inference results\n",
    "result_return = post_process(result_list, orig, model._model_desc)\n",
    "#print(\"result = \", result_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf86bad-d1f0-4346-9f8e-a4874b295b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:./out/out_test.jpg\n",
      "Execute end\n"
     ]
    }
   ],
   "source": [
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (0, 255, 255), (255, 0, 255), (255, 255, 0)]\n",
    "for i in range(len(result_return['detection_classes'])):\n",
    "    box = result_return['detection_boxes'][i]\n",
    "    class_name = result_return['detection_classes'][i]\n",
    "    confidence = result_return['detection_scores'][i]\n",
    "    cv.rectangle(bgr_img, (int(box[1]), int(box[0])), (int(box[3]), int(box[2])), colors[i % 6])\n",
    "    p3 = (max(int(box[1]), 15), max(int(box[0]), 15))\n",
    "    out_label = class_name            \n",
    "    cv.putText(bgr_img, out_label, p3, cv.FONT_ITALIC, 0.6, colors[i % 6], 2)\n",
    "\n",
    "output_file = os.path.join(OUTPUT_DIR, \"out_\" + os.path.basename(pic))\n",
    "print(\"output:%s\" % output_file)\n",
    "cv.imwrite(output_file, bgr_img)\n",
    "print(\"Execute end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354451f0-8679-478e-9cad-c569fdb64624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./out/out_test.jpg']\n"
     ]
    }
   ],
   "source": [
    "images_list = [os.path.join(OUTPUT_DIR, img)\n",
    "                   for img in os.listdir(OUTPUT_DIR)\n",
    "                   if os.path.splitext(img)[1] in const.IMG_EXT]\n",
    "print(images_list)\n",
    "output_img = cv.imread(images_list[0])\n",
    "res_img = cv.cvtColor(output_img, cv.COLOR_BGR2RGB)\n",
    "res_img_plw = Image.fromarray(res_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2984ea-fd90-463f-9d7e-ec4169c90eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_img_plw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b977fd-a107-449c-a0f5-c3ca92946121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
