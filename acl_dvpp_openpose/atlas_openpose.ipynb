{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acl\n",
    "import numpy as np\n",
    "import struct\n",
    "from constant import ACL_MEM_MALLOC_NORMAL_ONLY, \\\n",
    "    ACL_MEMCPY_HOST_TO_DEVICE, ACL_MEMCPY_DEVICE_TO_HOST, \\\n",
    "    ACL_ERROR_NONE, NPY_BYTE\n",
    "from PIL import Image\n",
    "from postprocessing import estimate_paf, draw_humans\n",
    "from acl_sample import Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sample] init resource stage:\n",
      "[Sample] init resource stage success\n",
      "[Model] class Model init resource stage:\n",
      "model output size 3\n",
      "output  0\n",
      "model output dims ({'name': 'peaks:0', 'dimCount': 4, 'dims': [1, 92, 92, 19]}, 0)\n",
      "model output datatype 0\n",
      "output  1\n",
      "model output dims ({'name': 'heatmat_output:0', 'dimCount': 4, 'dims': [1, 92, 92, 19]}, 0)\n",
      "model output datatype 0\n",
      "output  2\n",
      "model output dims ({'name': 'pafmat_output:0', 'dimCount': 4, 'dims': [1, 92, 92, 38]}, 0)\n",
      "model output datatype 0\n",
      "[Model] create model output dataset:\n",
      "[Model] create model output dataset success\n",
      "[Model] class Model init resource stage success\n"
     ]
    }
   ],
   "source": [
    "sample = Sample(0,\n",
    "                \"./model/openpose_from_tf.om\",\n",
    "                368,\n",
    "                368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict = {\"path\": \"./data/p3.jpg\", \"dtype\": np.uint8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sample] width:600 height:471\n",
      "[Sample] image:./data/p3.jpg\n",
      "[Dvpp] vpc decode stage:\n",
      "[Dvpp] vpc decode stage success\n",
      "[Dvpp] vpc resize stage:\n",
      "[Dvpp] vpc resize stage success\n",
      "dvpp_output_size 203136\n",
      "[Model] create model input dataset:\n",
      "[Model] create model input dataset success\n",
      "[Model] execute stage:\n",
      "[Model] execute stage success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Sample.__del__ of <acl_sample.Sample object at 0xfffefc3a4358>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/HwHiAiUser/pyACL_samples/acl_execute_model/acl_dvpp_openpose/acl_sample.py\", line 48, in __del__\n",
      "    if self.model_process:\n",
      "AttributeError: 'Sample' object has no attribute 'model_process'\n",
      "Exception ignored in: <bound method Model.__del__ of <acl_model.Model object at 0xfffefc3a4a20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/HwHiAiUser/pyACL_samples/acl_execute_model/acl_dvpp_openpose/acl_model.py\", line 34, in __del__\n",
      "    self._release_dataset()\n",
      "  File \"/home/HwHiAiUser/pyACL_samples/acl_execute_model/acl_dvpp_openpose/acl_model.py\", line 113, in _release_dataset\n",
      "    for dataset in [self.input_dataset, self.output_data]:\n",
      "AttributeError: 'Model' object has no attribute 'input_dataset'\n"
     ]
    }
   ],
   "source": [
    "model_output = sample.forward(img_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output = acl.mdl.get_dataset_num_buffers(model_output)\n",
    "\n",
    "def get_model_output_by_index(model_output, i):\n",
    "    temp_output_buf = acl.mdl.get_dataset_buffer(model_output, i)\n",
    "\n",
    "    infer_output_ptr = acl.get_data_buffer_addr(temp_output_buf)\n",
    "    infer_output_size = acl.get_data_buffer_size(temp_output_buf)\n",
    "#     print(\"infer_output_size\", infer_output_size)\n",
    "    \n",
    "#     output_host, _ = acl.rt.malloc_host(infer_output_size)\n",
    "#     acl.rt.memcpy(output_host, infer_output_size, infer_output_ptr,\n",
    "#                           infer_output_size, ACL_MEMCPY_DEVICE_TO_HOST)\n",
    "    \n",
    "    result = acl.util.ptr_to_numpy(infer_output_ptr, (infer_output_size,), NPY_BYTE)\n",
    "    return np.array(struct.unpack(f\"{infer_output_size//4}f\", bytearray(result)), dtype=np.float32).reshape(92, 92, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peaks = get_model_output_by_index(model_output, 0)\n",
    "heatmat = get_model_output_by_index(model_output, 1)\n",
    "pafmat = get_model_output_by_index(model_output, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = estimate_paf(peaks, heatmat, pafmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = draw_humans(np.array(Image.open(img_dict[\"path\"])), humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
