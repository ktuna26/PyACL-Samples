{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a91e58-1ee8-40ad-9832-ba257b046808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2022 Huawei Technologies Co., Ltd\n",
    "\n",
    "CREATED:  2020-12-19 20:12:13\n",
    "MODIFIED: 2022-12-28 15:48:45\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from src.preprocessing import preprocessing, distance\n",
    "from src.model import Model, execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9daf42b1-7522-4780-a5a8-fe06b5911348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image & model path\n",
    "image_path = \"facenet_data\"\n",
    "model_path = \"model/facenet_tf.pb\"\n",
    "\n",
    "# define input & output tensor names\n",
    "input_tensor_name = \"input:0\"\n",
    "output_tensor_name = \"embeddings:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a64864-17bb-4af2-843c-4472b2d99722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 18:15:27.709184: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2023-01-12 18:15:27.720032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2023-01-12 18:15:27.725099: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b4722f8a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-12 18:15:27.725129: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "# initialize Model \n",
    "model = Model(model_path,input_tensor_name,output_tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a300b8-8ad6-4adb-94a5-c1d6e0cb345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspace/pyacl_samples/pyacl_samples/TensorFlow/Online_FaceNet/src/preprocessing.py:33: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /workspace/pyacl_samples/pyacl_samples/TensorFlow/Online_FaceNet/src/preprocessing.py:36: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "# 1) pre-processing stage\n",
    "images, images_count, image_name_list = preprocessing(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1647a0af-42b0-4778-bc71-0125255ca7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n",
      "================== data (1, 160, 160, 3) float32\n"
     ]
    }
   ],
   "source": [
    "# 2) model execution(forward) stage\n",
    "batch_output, batch_time = execute(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be18563-deb8-4495-b5aa-2a8fca779f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Euclidean Distance\n",
      "Between ann4 and ann3: 1.449725\n",
      "Between ann4 and ann1: 0.746230\n",
      "Between ann4 and rand1: 0.862734\n",
      "Between ann4 and ann2: 0.673853\n",
      "Between ann3 and ann1: 1.093279\n",
      "Between ann3 and rand1: 1.361830\n",
      "Between ann3 and ann2: 1.073714\n",
      "Between ann1 and rand1: 0.824778\n",
      "Between ann1 and ann2: 0.210754\n",
      "Between rand1 and ann2: 0.999085\n",
      "\n",
      "==== Cosine Distance\n",
      "Between ann4 and ann3: 0.411277\n",
      "Between ann4 and ann1: 0.284330\n",
      "Between ann4 and rand1: 0.307472\n",
      "Between ann4 and ann2: 0.269252\n",
      "Between ann3 and ann1: 0.350225\n",
      "Between ann3 and rand1: 0.396624\n",
      "Between ann3 and ann2: 0.346722\n",
      "Between ann1 and rand1: 0.300068\n",
      "Between ann1 and ann2: 0.147444\n",
      "Between rand1 and ann2: 0.333165\n"
     ]
    }
   ],
   "source": [
    "assert len(image_name_list) == len(batch_output)\n",
    "\n",
    "print(\"==== Euclidean Distance\")\n",
    "for i in range(len(image_name_list)-1):\n",
    "    for j in range(i+1, len(image_name_list)):\n",
    "        print(\"Between %s and %s: %f\" % (image_name_list[i], image_name_list[j], distance(batch_output[i], batch_output[j])))\n",
    "print()\n",
    "print(\"==== Cosine Distance\")\n",
    "for i in range(len(image_name_list)-1):\n",
    "    for j in range(i+1, len(image_name_list)):\n",
    "        print(\"Between %s and %s: %f\" % (image_name_list[i], image_name_list[j], distance(batch_output[i], batch_output[j], distance_metric=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
